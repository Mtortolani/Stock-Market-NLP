{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PdfCleaner import PdfCleaner\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PerformanceTesting import PerformanceTester\n",
    "import pdfplumber\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "class Transcripts:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        xinyu = \"/Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project\"\n",
    "        marco = \"C:/Users/mtort/Repositories/DS3500-Final-Project\"\n",
    "        emily = \"/Users/emilywang/Desktop/DS3500-Final-Project-main-2\"\n",
    "        kelly = \"/Users/kelly/Desktop/ds3500/DS3500-Final-Project\"\n",
    "        qi = \"\"\n",
    "        self.path = emily + \"/transcripts/\"+ticker+\"_transcripts/\"\n",
    "\n",
    "    def read_files(self):\n",
    "        return [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
    "\n",
    "    def create_dct(self):\n",
    "        lst_files = self.read_files()\n",
    "        lst_cleaned = []\n",
    "        for file in lst_files:\n",
    "            file_path = self.path + file\n",
    "            if file_path[-3:] == 'pdf':\n",
    "                txt = PdfCleaner(file_path)\n",
    "                date = file[:8]\n",
    "                # txt_cleaned = txt.clean_stopwords_punctuation()\n",
    "                txt_cleaned = txt.clean_nums()\n",
    "                PerfTest = PerformanceTester()\n",
    "                PerfTest.setTimeframe('day', 1)\n",
    "                PerfTest.loadArticles([[self.ticker, date, txt_cleaned]])\n",
    "                try:\n",
    "                    classification_xy = PerfTest.aquireTargetValues()\n",
    "                except KeyError:\n",
    "                    print(f'''Warning: attempted to access market during weekend or after hours\n",
    "                          Earnings Transcript {file_path} Not Added\n",
    "                          ''')\n",
    "                    continue\n",
    "                dct_cleaned = {'price_change': classification_xy[1][0], 'name': self.ticker, 'date': date, 'transcript': txt_cleaned}\n",
    "                lst_cleaned.append(dct_cleaned)\n",
    "        return lst_cleaned\n",
    "\n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        client = MongoClient()\n",
    "        client.drop_database('transcripts')\n",
    "        self.db = client.transcripts\n",
    "\n",
    "    def store_data(self, tickers_lst):\n",
    "        for t in tickers_lst:\n",
    "            store = Transcripts(t)\n",
    "            transcript = store.create_dct()\n",
    "            self.db.transcript.insert_many(transcript)\n",
    "            print(t + \" transcripts stored successfully\")\n",
    "        return self.db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526178.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526172.pdf Not Added\n",
      "                          \n",
      "AAPL transcripts stored successfully\n",
      "FB transcripts stored successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' To prevent \"IOPub data rate exceeded error\":\n",
    "enter into terminal: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 '''\n",
    "\n",
    "tickers = ['AAPL', 'FB', 'MSFT']\n",
    "    # works: APPL, MSFT\n",
    "    # doesn't work: FB, GOOGL, NFLX, TSLA, ADBE, CMCSA, COST, AMZN\n",
    "\n",
    "    # 'APPL', 'MSFT', 'FB', 'GOOGL', 'NFLX', 'TSLA', 'ADBE', 'CMCSA', 'COST', 'AMZN'\n",
    "    # client = MongoClient()\n",
    "    # client.drop_database('transcripts')\n",
    "    # db = client.transcripts\n",
    "\n",
    "\n",
    "    # for t in tickers:\n",
    "    #     store = Transcripts(t)\n",
    "    #     transcript = store.create_dct()\n",
    "    #     # print(transcript)\n",
    "    #     db.transcript.insert_many(transcript)\n",
    "    #     print(t + \" transcripts stored successfully\")\n",
    "\n",
    "    # db.transcript.find() # client.transcripts.transcript.find()\n",
    "\n",
    "database = Database()\n",
    "db = database.store_data(tickers)\n",
    "# all_transcripts = db.transcript.find()\n",
    "# for transcript in all_transcripts:\n",
    "#     print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aapl</th>\n",
       "      <th>ab</th>\n",
       "      <th>abb</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absent</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬂip</th>\n",
       "      <th>ﬂoor</th>\n",
       "      <th>ﬂow</th>\n",
       "      <th>ﬂowing</th>\n",
       "      <th>ﬂows</th>\n",
       "      <th>ﬂuctuate</th>\n",
       "      <th>ﬂuctuation</th>\n",
       "      <th>ﬂuctuations</th>\n",
       "      <th>ﬂuid</th>\n",
       "      <th>ﬂywheel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.010291</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.012134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.114242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003321</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006568</td>\n",
       "      <td>0.011499</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063862</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006684</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.122199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.006781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010932</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010176</td>\n",
       "      <td>0.010767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.018455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028223</td>\n",
       "      <td>0.018855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 6081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aaa      aapl        ab  abb   ability      able  abnormally     about  \\\n",
       "0   0.0  0.123631  0.000000  0.0  0.003594  0.010291    0.012444  0.012134   \n",
       "1   0.0  0.114242  0.000000  0.0  0.003321  0.015849    0.000000  0.000000   \n",
       "2   0.0  0.063862  0.000000  0.0  0.006684  0.004253    0.000000  0.000000   \n",
       "3   0.0  0.062744  0.000000  0.0  0.000000  0.004477    0.000000  0.000000   \n",
       "4   0.0  0.122199  0.000000  0.0  0.003553  0.006781    0.000000  0.000000   \n",
       "..  ...       ...       ...  ...       ...       ...         ...       ...   \n",
       "80  0.0  0.000000  0.000000  0.0  0.003704  0.001768    0.000000  0.002084   \n",
       "81  0.0  0.000000  0.000000  0.0  0.003143  0.011998    0.000000  0.003537   \n",
       "82  0.0  0.000000  0.000000  0.0  0.017635  0.000000    0.000000  0.000000   \n",
       "83  0.0  0.000000  0.010182  0.0  0.006446  0.018455    0.000000  0.000000   \n",
       "84  0.0  0.000000  0.000000  0.0  0.028223  0.018855    0.000000  0.019055   \n",
       "\n",
       "       above  absent  ...  ﬂip      ﬂoor       ﬂow  ﬂowing      ﬂows  \\\n",
       "0   0.000000     0.0  ...  0.0  0.000000  0.004456     0.0  0.000000   \n",
       "1   0.000000     0.0  ...  0.0  0.000000  0.004118     0.0  0.000000   \n",
       "2   0.000000     0.0  ...  0.0  0.000000  0.000000     0.0  0.000000   \n",
       "3   0.000000     0.0  ...  0.0  0.000000  0.000000     0.0  0.000000   \n",
       "4   0.000000     0.0  ...  0.0  0.000000  0.004404     0.0  0.000000   \n",
       "..       ...     ...  ...  ...       ...       ...     ...       ...   \n",
       "80  0.000000     0.0  ...  0.0  0.000000  0.000000     0.0  0.000000   \n",
       "81  0.000000     0.0  ...  0.0  0.000000  0.023378     0.0  0.009551   \n",
       "82  0.000000     0.0  ...  0.0  0.000000  0.010932     0.0  0.000000   \n",
       "83  0.000000     0.0  ...  0.0  0.010182  0.007991     0.0  0.000000   \n",
       "84  0.010338     0.0  ...  0.0  0.000000  0.010497     0.0  0.008577   \n",
       "\n",
       "    ﬂuctuate  ﬂuctuation  ﬂuctuations      ﬂuid   ﬂywheel  \n",
       "0   0.000000    0.000000     0.000000  0.000000  0.000000  \n",
       "1   0.000000    0.000000     0.006568  0.011499  0.000000  \n",
       "2   0.000000    0.000000     0.000000  0.000000  0.000000  \n",
       "3   0.000000    0.000000     0.000000  0.000000  0.000000  \n",
       "4   0.000000    0.000000     0.000000  0.000000  0.000000  \n",
       "..       ...         ...          ...       ...       ...  \n",
       "80  0.000000    0.000000     0.000000  0.000000  0.000000  \n",
       "81  0.000000    0.000000     0.006215  0.000000  0.000000  \n",
       "82  0.010176    0.010767     0.000000  0.000000  0.000000  \n",
       "83  0.000000    0.000000     0.006374  0.000000  0.011158  \n",
       "84  0.000000    0.000000     0.005581  0.000000  0.000000  \n",
       "\n",
       "[85 rows x 6081 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "''' Query to test on all APPLE transcripts '''\n",
    "# apple = db.transcript.find({\"name\":\"APPL\"})\n",
    "\n",
    "\n",
    "''' Query to test on all transcripts '''\n",
    "all_companies = db.transcript.find()\n",
    "\n",
    "data = {}\n",
    "text = []\n",
    "\n",
    "for transcript in all_companies:\n",
    "    data[transcript[\"name\"]+\" \"+transcript[\"date\"]] = transcript[\"transcript\"]\n",
    "    text.append(transcript[\"transcript\"])\n",
    "#     print(transcript)\n",
    "#     df = pd.DataFrame.from_dict(data, orient ='index')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for name, info in data.items():\n",
    "''' Use countvectorizer to convert pdf text to a matrix of token counts '''\n",
    "# vect = CountVectorizer()\n",
    "# vect.fit(text)\n",
    "#     print(\"vocabulary: \\n\", vect.vocabulary_)\n",
    "\n",
    "\n",
    "''' Use bag of words to count how many times each word appears in pdf '''\n",
    "# bag_of_words = vect.transform(text)\n",
    "#     print(bag_of_words)\n",
    "\n",
    "    # number of times each unique word appears in this text\n",
    "# bag_of_words_arr = bag_of_words.toarray()\n",
    "# #     print(bag_of_words_arr)\n",
    "# feature_names = vect.get_feature_names()\n",
    "#     print(feature_names)\n",
    "\n",
    "''' Display occurrences in dataframe '''\n",
    "# bow_df = pd.DataFrame(bag_of_words_arr, columns = feature_names)\n",
    "# bow_df[\"Transcript (Company)\"] = \"APPL\"\n",
    "# bow_df.set_index(\"Transcript (Company & Date)\", inplace=True)\n",
    "\n",
    "''' Use Tfidf vectorizer to match words to TFIDF values '''\n",
    "\n",
    "vect = TfidfVectorizer(min_df=3, ngram_range = (1, 1)).fit(text)\n",
    "bag_of_words = vect.transform(text)\n",
    "feature_names = vect.get_feature_names()\n",
    "    \n",
    "tfidf_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "# tfidf_df[name] = text\n",
    "# tfidf_df.set_index(name, inplace=True)\n",
    "\n",
    "# tfidf_df.head()\n",
    "    \n",
    "    \n",
    "# tfidfconverter = TfidfTransformer()\n",
    "# X = tfidfconverter.fit_transform(bag_of_words_arr).toarray()\n",
    "\n",
    "    \n",
    "# tfidf_df = pd.DataFrame(X, columns = feature_names)\n",
    "# tfidf_df[\"Transcript (Company)\"] = \"APPL\"\n",
    "# tfidf_df.set_index(\"Transcript (Company & Date)\", inplace=True)\n",
    "\n",
    "# ''' Show number of occurences of each word in one dataframe and tfidf (weighted) values of each word in another\n",
    "#     dataframe for each pdf '''\n",
    "# display(bow_df)\n",
    "display(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-14.370612</td>\n",
       "      <td>34.929522</td>\n",
       "      <td>6.866992</td>\n",
       "      <td>0.138975</td>\n",
       "      <td>43.083945</td>\n",
       "      <td>26.666641</td>\n",
       "      <td>-12.637670</td>\n",
       "      <td>2.212028</td>\n",
       "      <td>-0.841859</td>\n",
       "      <td>46.323495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-10.497373</td>\n",
       "      <td>30.210806</td>\n",
       "      <td>8.287971</td>\n",
       "      <td>-1.123895</td>\n",
       "      <td>7.018501</td>\n",
       "      <td>7.353379</td>\n",
       "      <td>3.098508</td>\n",
       "      <td>4.250223</td>\n",
       "      <td>-11.627328</td>\n",
       "      <td>-6.280092</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7.212433</td>\n",
       "      <td>23.007934</td>\n",
       "      <td>-14.789445</td>\n",
       "      <td>-2.624524</td>\n",
       "      <td>-15.767124</td>\n",
       "      <td>1.323900</td>\n",
       "      <td>41.466960</td>\n",
       "      <td>0.129794</td>\n",
       "      <td>2.039342</td>\n",
       "      <td>11.192966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.380730</td>\n",
       "      <td>21.070138</td>\n",
       "      <td>-19.801125</td>\n",
       "      <td>-5.100650</td>\n",
       "      <td>8.929719</td>\n",
       "      <td>-0.864220</td>\n",
       "      <td>-8.200650</td>\n",
       "      <td>-4.622732</td>\n",
       "      <td>13.711437</td>\n",
       "      <td>-12.145730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-11.972317</td>\n",
       "      <td>33.472015</td>\n",
       "      <td>9.580812</td>\n",
       "      <td>2.456007</td>\n",
       "      <td>-13.667796</td>\n",
       "      <td>-0.405706</td>\n",
       "      <td>17.977278</td>\n",
       "      <td>5.968215</td>\n",
       "      <td>-10.963286</td>\n",
       "      <td>-20.793990</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>16.662866</td>\n",
       "      <td>-2.316088</td>\n",
       "      <td>-22.087908</td>\n",
       "      <td>-11.311856</td>\n",
       "      <td>-0.363315</td>\n",
       "      <td>-12.725377</td>\n",
       "      <td>3.746636</td>\n",
       "      <td>-2.113741</td>\n",
       "      <td>16.417479</td>\n",
       "      <td>-1.375908</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>35.193460</td>\n",
       "      <td>-5.580390</td>\n",
       "      <td>11.409932</td>\n",
       "      <td>-9.951625</td>\n",
       "      <td>1.666313</td>\n",
       "      <td>6.644126</td>\n",
       "      <td>-1.139479</td>\n",
       "      <td>-1.144222</td>\n",
       "      <td>5.156290</td>\n",
       "      <td>-2.746820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>38.160879</td>\n",
       "      <td>-6.107779</td>\n",
       "      <td>-4.026217</td>\n",
       "      <td>70.652309</td>\n",
       "      <td>1.297173</td>\n",
       "      <td>18.620154</td>\n",
       "      <td>2.366126</td>\n",
       "      <td>-11.780831</td>\n",
       "      <td>7.724605</td>\n",
       "      <td>-5.789132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>35.070542</td>\n",
       "      <td>-7.415929</td>\n",
       "      <td>22.115346</td>\n",
       "      <td>-19.827102</td>\n",
       "      <td>-3.290288</td>\n",
       "      <td>16.520365</td>\n",
       "      <td>2.833955</td>\n",
       "      <td>-18.532044</td>\n",
       "      <td>-1.904825</td>\n",
       "      <td>-0.470039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>32.015757</td>\n",
       "      <td>-4.076513</td>\n",
       "      <td>-0.276841</td>\n",
       "      <td>9.038884</td>\n",
       "      <td>0.347045</td>\n",
       "      <td>-7.730550</td>\n",
       "      <td>-7.552944</td>\n",
       "      <td>21.509507</td>\n",
       "      <td>-7.238386</td>\n",
       "      <td>5.930832</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3          4          5  \\\n",
       "0  -14.370612  34.929522   6.866992   0.138975  43.083945  26.666641   \n",
       "1  -10.497373  30.210806   8.287971  -1.123895   7.018501   7.353379   \n",
       "2   -7.212433  23.007934 -14.789445  -2.624524 -15.767124   1.323900   \n",
       "3   -7.380730  21.070138 -19.801125  -5.100650   8.929719  -0.864220   \n",
       "4  -11.972317  33.472015   9.580812   2.456007 -13.667796  -0.405706   \n",
       "..        ...        ...        ...        ...        ...        ...   \n",
       "80  16.662866  -2.316088 -22.087908 -11.311856  -0.363315 -12.725377   \n",
       "81  35.193460  -5.580390  11.409932  -9.951625   1.666313   6.644126   \n",
       "82  38.160879  -6.107779  -4.026217  70.652309   1.297173  18.620154   \n",
       "83  35.070542  -7.415929  22.115346 -19.827102  -3.290288  16.520365   \n",
       "84  32.015757  -4.076513  -0.276841   9.038884   0.347045  -7.730550   \n",
       "\n",
       "            6          7          8          9  target  \n",
       "0  -12.637670   2.212028  -0.841859  46.323495       0  \n",
       "1    3.098508   4.250223 -11.627328  -6.280092       0  \n",
       "2   41.466960   0.129794   2.039342  11.192966       1  \n",
       "3   -8.200650  -4.622732  13.711437 -12.145730       1  \n",
       "4   17.977278   5.968215 -10.963286 -20.793990       0  \n",
       "..        ...        ...        ...        ...     ...  \n",
       "80   3.746636  -2.113741  16.417479  -1.375908       1  \n",
       "81  -1.139479  -1.144222   5.156290  -2.746820       0  \n",
       "82   2.366126 -11.780831   7.724605  -5.789132       1  \n",
       "83   2.833955 -18.532044  -1.904825  -0.470039       1  \n",
       "84  -7.552944  21.509507  -7.238386   5.930832       0  \n",
       "\n",
       "[85 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "''' Using PCA to reduce total number of features before feeding into ML model '''\n",
    "# instantiate the PCA object and request ten components (reduces number of columns/features)\n",
    "pca = PCA(n_components=10, random_state=3000)\n",
    "\n",
    "\n",
    "# standardize the features so they are all on the same scale\n",
    "features_standardized = StandardScaler().fit_transform(bag_of_words.toarray())\n",
    "\n",
    "# transform the standardized features using the PCA algorithm \n",
    "reduced_data = pca.fit_transform(features_standardized)\n",
    "\n",
    "# show transformed results in dataframe\n",
    "components = [\"Component1\", \"Component2\", \"Component3\", \"Component4\", \"Component5\", \"Component6\",\n",
    "             \"Component7\", \"Component8\", \"Component9\", \"Component10\"]\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_data)#, columns = components)\n",
    "\n",
    "''' Obtain target values (whether stock price increased, decreased, or stayed the same) \n",
    "from database '''\n",
    "price_changes = []\n",
    "all_transcripts = db.transcript.find()\n",
    "for transcript in all_transcripts:\n",
    "    price_changes.append(transcript['price_change'])\n",
    "\n",
    "pca_df['target'] = price_changes \n",
    "\n",
    "pca_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
