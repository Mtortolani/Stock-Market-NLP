{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h3> DS 3500 — Fall 2021</h3> </center>\n",
    "<center><h1> Natural Language Processing and Supervised Machine Learning Methods to Predict Stock Price Change from Earnings Call Transcripts </h1></center> \n",
    "<center><h4>  By: Qi Li, Kelly Phalen, Marco Tortolani, Emily Wang, Xinyu Wu </h4></center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "[1. PDFCleaner](#1.-PDFCleaner)\n",
    "\n",
    "[2. StockPuller](#2.-StockPuller)\n",
    "\n",
    "[3. PerformanceTester](#3.-PerformanceTester)\n",
    "\n",
    "[4. Transcripts](#4.-Transcripts)\n",
    "\n",
    "[5. Database](#5.-Database)\n",
    "\n",
    "[6. Vectorizers](#6.-Vectorizers)\n",
    "\n",
    "[7. Principal Component Analysis](#7.-Principal-Component-Analysis)\n",
    "\n",
    "[8. Base Models](#8.-Base-Models)\n",
    "\n",
    "[9. Hyperparameter Tuning](#9.-Hyperparameter-Tuning)\n",
    "\n",
    "[10. Model Performance](#10.-Model-Performance)\n",
    "\n",
    "[11. Cross-Validation](#11.-Cross-Validation)\n",
    "\n",
    "[12. Visualizations](#12.-Visualizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PDFCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PdfCleaner:\n",
    "  def __init__ (self,pdf_file_path):\n",
    "    self.__path__ = pdf_file_path\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(self.__path__) as pdf:\n",
    "      for i in range(len(pdf.pages)):\n",
    "        page = pdf.pages[i]\n",
    "        text = text + str(page.extract_text())\n",
    "    self.__original_text__ = text\n",
    "    self.__cleaned_text__= self.clean_stopwords_punctuation()\n",
    "    self.__nonum_text__ = self.clean_nums()\n",
    "\n",
    "  def lenBeforeClean(self):\n",
    "    return len(self.__original_text__)\n",
    "\n",
    "  def lenAfterClean(self):\n",
    "    return len(self.__cleaned_text__)\n",
    "\n",
    "  def print_originalText(self):\n",
    "    print(self.__original_text__)\n",
    "\n",
    "  def print_cleanedText(self):\n",
    "    print(self.__cleaned_text__)\n",
    "\n",
    "  def clean_stopwords_punctuation(self):\n",
    "    cleaned_text = remove_stopwords(self.__original_text__)\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~©'''\n",
    "    for ele in cleaned_text:\n",
    "      if ele in punc:\n",
    "         cleaned_text = cleaned_text.replace(ele, \"\")\n",
    "    return cleaned_text\n",
    "\n",
    "  def clean_nums(self):\n",
    "    nonum_text = re.sub(r'\\d+', '', self.__cleaned_text__)\n",
    "    return nonum_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. StockPuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    " \n",
    "class StockPuller:\n",
    "    def __init__(self):\n",
    "        self. tickerList = ['AAPL', 'ADBE', 'AMZN', 'ASML', 'AVGO', 'CMCSA', 'COST',  'CSCO', 'FB', 'GOOGL',\n",
    "           'INTC', 'MSFT', 'NFLX', 'NVDA', 'PDD', 'PEP', 'PYPL', 'TMUS', 'TSLA', 'TXN']\n",
    "       \n",
    "    # get historical market data\n",
    "    def plotAll(self):\n",
    "        for ticker in self.tickerList:\n",
    "            ticker = yf.Ticker(ticker)\n",
    "            hist = ticker.history(period='5y', interval='1d')\n",
    "            hist[\"Close\"].plot(figsize=(16,9))\n",
    "        plt.legend(self.tickerList)\n",
    "        plt.show()\n",
    "   \n",
    "    def plotStock(self, ticker):\n",
    "        stock = yf.Ticker(ticker)\n",
    "        hist = stock.history(period='5y', interval='1d')\n",
    "        hist[\"Close\"].plot(figsize=(16,9))\n",
    "        plt.legend([ticker])\n",
    "        plt.show()\n",
    " \n",
    "    def dailyData(self, ticker):\n",
    "        stock = yf.Ticker(ticker)\n",
    "        stockData = stock.history(period='5y',interval='1d')\n",
    "        print(stockData)\n",
    " \n",
    "    def changeOverDays(self, ticker, startDate, days):\n",
    "        '''\n",
    "        Returns the % change of a stocks value in a certan timeframe\n",
    " \n",
    "        Parameters:\n",
    "        ticker (str): stock ticker (ex. 'AAPL')\n",
    "        startDate (str): the day which to start the comparison (ex. '2021-11-02')\n",
    "        days (int): days that pass on which to compare closing values\n",
    "       \n",
    "        Bugfix:\n",
    "        market isnt open on weekends\n",
    "        '''\n",
    "        stock = yf.Ticker(ticker)\n",
    "        stockData = stock.history(period='5y', interval='1d')\n",
    " \n",
    "        startDatetime = datetime.strptime(startDate, '%Y%m%d')\n",
    "        endDatetime = startDatetime + timedelta(days=days)\n",
    "        # try:\n",
    "        #     startPrice = stockData.loc[startDatetime]['Open']\n",
    "        #     endPrice = stockData.loc[endDatetime]['Close']\n",
    "        # except:\n",
    "        #     return KeyError('Attempted to access Date or Hour during closed market')\n",
    "        \n",
    "        startPrice = stockData.loc[startDatetime]['Open']\n",
    "        endPrice = stockData.loc[endDatetime]['Close']\n",
    "        changeInPrice = startPrice / endPrice\n",
    "        return changeInPrice - 1\n",
    " \n",
    "    def changeOverHours(self, ticker, startDate, hours):\n",
    "        '''\n",
    "        Returns the % change of a stocks value in a certan timeframe\n",
    " \n",
    "        Parameters:\n",
    "        ticker (str): stock ticker (ex. 'AAPL')\n",
    "        startDate (str): the day and time which to start the comparison (ex. '2021-11-02 11:30:00') NOTE: only put in 30 minute intervals\n",
    "        hours (int): hours that pass on which to compare closing values\n",
    "       \n",
    "        Bugfix:\n",
    "        market isnt open on weekends\n",
    "        only takes in half hour inputs\n",
    "        '''\n",
    "        stock = yf.Ticker(ticker)\n",
    "        stockData = stock.history(period='2y', interval='1h')\n",
    "        stockData.index = stockData.index.tz_localize(None)\n",
    "       \n",
    "        # TO DO: limit to only allow times within market open/closing hours (9:30am-4:30pm)\n",
    "        try:\n",
    "            startDatetime = datetime.strptime(startDate, '%Y-%m-%d %H:%M:%S')\n",
    "            endDatetime = startDatetime + timedelta(hours=hours)\n",
    "        except:\n",
    "            raise Exception('You are checking for time after market closing hours')\n",
    " \n",
    "        startPrice = stockData.loc[startDatetime]['Open']\n",
    "        endPrice = stockData.loc[endDatetime]['Close']\n",
    "        changeInPrice = (startPrice / endPrice) - 1\n",
    "        return changeInPrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PerformanceTester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceTester:\n",
    "    def __init__(self) -> None:\n",
    "        articleData = []\n",
    "       \n",
    "        timeFrame = 'day'\n",
    "        preferredTimespan = 1\n",
    "   \n",
    "    def loadArticles(self, articleList):\n",
    "        '''\n",
    "        Loads article data [ticker, date, transcript] into the PerformanceTester interior variable\n",
    " \n",
    "        Parameters:\n",
    "            articleList (list): a nested list in the form [ticker, date, transcript].This is stock ticker, the date of a report, and the transcript text\n",
    "        '''\n",
    "        self.articleData = articleList\n",
    "   \n",
    "    def setTimeframe(self, frame='day', span=1):\n",
    "        '''\n",
    "        Sets timeframe\n",
    " \n",
    "        Parameters:\n",
    "            frame (str): what unit (day or hour) are we using to look ahead\n",
    "            span (int): how many units forward forward do you want the tester to test\n",
    "        '''\n",
    "        if frame == 'hour':\n",
    "            self.timeframe = 'hour'\n",
    "        elif frame == 'day':\n",
    "            self.timeframe = 'day'\n",
    "        else:\n",
    "            raise Exception('invalid frame')\n",
    "        self.preferredTimespan = span\n",
    "   \n",
    "    def aquireTargetValues(self):\n",
    "        '''\n",
    "        Creates x values (list of articles) and y values (list of stock price change after article release) for nlp training\n",
    "        '''\n",
    "        x_values = [article[2] for article in self.articleData]\n",
    "        y_values = []\n",
    "        Puller = StockPuller()\n",
    "        for article in self.articleData:\n",
    "            if self.timeframe == 'day':\n",
    "                priceChange = Puller.changeOverDays(article[0], article[1], self.preferredTimespan)\n",
    "            elif self.timeframe == 'hour':\n",
    "                priceChange = Puller.changeOverHours(article[0], article[1], self.preferredTimespan)\n",
    "            else:\n",
    "                raise Exception('Please choose a reference type (\\'hour\\' or \\'day\\') using function setTimeframe')\n",
    "            if priceChange >= 0:\n",
    "                priceChange = 1\n",
    "            else:\n",
    "                priceChange = 0\n",
    "            y_values.append(priceChange)\n",
    "        return [x_values, y_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcripts:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        xinyu = \"/Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project\"\n",
    "        marco = \"C:/Users/mtort/Repositories/DS3500-Final-Project\"\n",
    "        emily = \"/Users/emilywang/Desktop/DS3500-Final-Project-main-2\"\n",
    "        kelly = \"/Users/kelly/Desktop/ds3500/DS3500-Final-Project\"\n",
    "        qi = \"\"\n",
    "        self.path = xinyu + \"/transcripts/\"+ticker+\"_transcripts/\"\n",
    "\n",
    "    def read_files(self):\n",
    "        return [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
    "\n",
    "    def create_dct(self):\n",
    "        lst_files = self.read_files()\n",
    "        lst_cleaned = []\n",
    "        for file in lst_files:\n",
    "            file_path = self.path + file\n",
    "            if file_path[-3:] == 'pdf':\n",
    "                txt = PdfCleaner(file_path)\n",
    "                date = file[:8]\n",
    "                txt_cleaned = txt.clean_nums()\n",
    "                PerfTest = PerformanceTester()\n",
    "                PerfTest.setTimeframe('day', 1)\n",
    "                PerfTest.loadArticles([[self.ticker, date, txt_cleaned]])\n",
    "                try:\n",
    "                    classification_xy = PerfTest.aquireTargetValues()\n",
    "                except KeyError:\n",
    "                    print(f'''Warning: attempted to access market during weekend or after hours\n",
    "                          Earnings Transcript {file_path} Not Added\n",
    "                          ''')\n",
    "                    continue\n",
    "                dct_cleaned = {'price_change': classification_xy[1][0], 'name': self.ticker, 'date': date, 'transcript': txt_cleaned}\n",
    "                lst_cleaned.append(dct_cleaned)\n",
    "        return lst_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database:\n",
    "    def __init__(self):\n",
    "        client = MongoClient()\n",
    "        client.drop_database('transcripts')\n",
    "        self.db = client.transcripts\n",
    "\n",
    "    def store_data(self, tickers_lst):\n",
    "        for t in tickers_lst:\n",
    "            store = Transcripts(t)\n",
    "            transcript = store.create_dct()\n",
    "            self.db.transcript.insert_many(transcript)\n",
    "            print(t + \" transcripts stored successfully\")\n",
    "        return self.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Transcripts for Top 20 NASDAQ Companies by Market Cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526178.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526172.pdf Not Added\n",
      "                          \n",
      "AAPL transcripts stored successfully\n",
      "ADBE transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/AMZN_transcripts/20190426_Amazon.com_Inc-_Earnings_Call_2019-4-25_DN000000002663104261.pdf Not Added\n",
      "                          \n",
      "AMZN transcripts stored successfully\n",
      "ASML transcripts stored successfully\n",
      "AVGO transcripts stored successfully\n",
      "CMCSA transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/COST_transcripts/20170303_COSTCO_WHOLESALE-_Earnings_Call_2017-3-2_FS000000002333920108.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/COST_transcripts/20170303_COSTCO_WHOLESALE-_Earnings_Call_2017-3-2_FS000000002333920096.pdf Not Added\n",
      "                          \n",
      "COST transcripts stored successfully\n",
      "CSCO transcripts stored successfully\n",
      "FB transcripts stored successfully\n",
      "GOOGL transcripts stored successfully\n",
      "INTC transcripts stored successfully\n",
      "MSFT transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/NFLX_transcripts/20190118_Netflix_Inc-_Earnings_Call_2019-1-17_DN000000002573718691.pdf Not Added\n",
      "                          \n",
      "NFLX transcripts stored successfully\n",
      "NVDA transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PDD_transcripts/20200522_Pinduoduo_Inc-_Earnings_Call_2020-5-22_DN000000002842636277.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PDD_transcripts/20200821_Pinduoduo_Inc-_Earnings_Call_2020-8-21_DN000000002890027659.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PDD_transcripts/20211126_Pinduoduo_Inc-_Earnings_Call_2021-11-26_RT000000002968946789.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PDD_transcripts/20180831_Pinduoduo_Inc-_Earnings_Call_2018-8-30_FS000000002463232018.pdf Not Added\n",
      "                          \n",
      "PDD transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PEP_transcripts/20190215_PepsiCo_Inc-_Earnings_Call_2019-2-15_FS000000002586060820.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/PEP_transcripts/20190215_PepsiCo_Inc-_Earnings_Call_2019-2-15_FS000000002586060802.pdf Not Added\n",
      "                          \n",
      "PEP transcripts stored successfully\n",
      "PYPL transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project/transcripts/TMUS_transcripts/20190726_T_Mobile_US_Inc-_Earnings_Call_2019-7-26_DN000000002676607927.pdf Not Added\n",
      "                          \n",
      "TMUS transcripts stored successfully\n",
      "TSLA transcripts stored successfully\n",
      "TXN transcripts stored successfully\n"
     ]
    }
   ],
   "source": [
    "''' To prevent \"IOPub data rate exceeded error\":\n",
    "enter into terminal: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 '''\n",
    "\n",
    "tickers = ['AAPL', 'ADBE', 'AMZN', 'ASML', 'AVGO', 'CMCSA', 'COST',  'CSCO', 'FB', 'GOOGL',\n",
    "           'INTC', 'MSFT', 'NFLX', 'NVDA', 'PDD', 'PEP', 'PYPL', 'TMUS', 'TSLA', 'TXN']\n",
    "\n",
    "database = Database()\n",
    "db = database.store_data(tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data():\n",
    "    ''' Function to query for all transcripts and store as list '''\n",
    "    all_companies = db.transcript.find()\n",
    "\n",
    "    data = {}\n",
    "    text = []\n",
    "\n",
    "    for transcript in all_companies:\n",
    "        data[transcript[\"name\"]+\" \"+transcript[\"date\"]] = transcript[\"transcript\"]\n",
    "        text.append(transcript[\"transcript\"])\n",
    "    \n",
    "    return data, text\n",
    "\n",
    "def tfidf(text):\n",
    "    ''' Tfidf vectorizer to match words to TFIDF values '''\n",
    "    vect = TfidfVectorizer(min_df=3, ngram_range = (1, 1)).fit(text)\n",
    "    bag_of_words = vect.transform(text)\n",
    "    feature_names = vect.get_feature_names()\n",
    "\n",
    "    tfidf_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "    display(tfidf_df)\n",
    "    return tfidf_df, bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abating</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬂuctuates</th>\n",
       "      <th>ﬂuctuation</th>\n",
       "      <th>ﬂuctuations</th>\n",
       "      <th>ﬂuid</th>\n",
       "      <th>ﬂuidity</th>\n",
       "      <th>ﬂush</th>\n",
       "      <th>ﬂux</th>\n",
       "      <th>ﬂy</th>\n",
       "      <th>ﬂying</th>\n",
       "      <th>ﬂywheel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 14903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaa      aapl     aaron   ab  abandon  abandoned  abandonment  abate  \\\n",
       "0    0.0  0.180664  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "1    0.0  0.165782  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "2    0.0  0.104560  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "3    0.0  0.104032  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "4    0.0  0.182241  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "..   ...       ...       ...  ...      ...        ...          ...    ...   \n",
       "543  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "544  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "545  0.0  0.000000  0.027292  0.0      0.0        0.0          0.0    0.0   \n",
       "546  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "547  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "\n",
       "     abatement  abating  ...  ﬂuctuates  ﬂuctuation  ﬂuctuations      ﬂuid  \\\n",
       "0          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "1          0.0      0.0  ...        0.0         0.0     0.007406  0.009567   \n",
       "2          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "3          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "4          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "..         ...      ...  ...        ...         ...          ...       ...   \n",
       "543        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "544        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "545        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "546        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "547        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "\n",
       "     ﬂuidity  ﬂush  ﬂux   ﬂy  ﬂying  ﬂywheel  \n",
       "0        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "1        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "2        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "3        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "4        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "..       ...   ...  ...  ...    ...      ...  \n",
       "543      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "544      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "545      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "546      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "547      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "\n",
       "[548 rows x 14903 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, text = query_data()\n",
    "tfidf_df, bag_of_words = tfidf(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_df(bag_of_words):\n",
    "    ''' PCA to reduce total number of features before feeding into ML model '''\n",
    "    # instantiate the PCA object and request reduced number of components (reduces number of columns/features)\n",
    "    pca = PCA(n_components=150, random_state=3000)\n",
    "\n",
    "\n",
    "    # standardize the features so they are all on the same scale\n",
    "    features_standardized = StandardScaler().fit_transform(bag_of_words.toarray())\n",
    "\n",
    "    # transform the standardized features using the PCA algorithm \n",
    "    reduced_data = pca.fit_transform(features_standardized)\n",
    "\n",
    "    # show transformed results in dataframe\n",
    "    pca_df = pd.DataFrame(reduced_data)#, columns = components)\n",
    "\n",
    "    ''' Obtain target values (whether stock price increased, decreased, or stayed the same) \n",
    "    from database '''\n",
    "    price_changes = []\n",
    "    all_transcripts = db.transcript.find()\n",
    "    for transcript in all_transcripts:\n",
    "        price_changes.append(transcript['price_change'])\n",
    "\n",
    "    pca_df['target'] = price_changes \n",
    "\n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.346558</td>\n",
       "      <td>-4.687576</td>\n",
       "      <td>-6.215062</td>\n",
       "      <td>5.370536</td>\n",
       "      <td>-1.404635</td>\n",
       "      <td>-4.559129</td>\n",
       "      <td>13.821442</td>\n",
       "      <td>16.252597</td>\n",
       "      <td>49.966649</td>\n",
       "      <td>51.039385</td>\n",
       "      <td>...</td>\n",
       "      <td>2.896040</td>\n",
       "      <td>1.992734</td>\n",
       "      <td>-1.870281</td>\n",
       "      <td>0.705100</td>\n",
       "      <td>6.747039</td>\n",
       "      <td>1.281073</td>\n",
       "      <td>-2.736667</td>\n",
       "      <td>-2.002284</td>\n",
       "      <td>-2.784893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.123418</td>\n",
       "      <td>-6.398258</td>\n",
       "      <td>-5.925861</td>\n",
       "      <td>1.778670</td>\n",
       "      <td>-1.360708</td>\n",
       "      <td>-1.191740</td>\n",
       "      <td>7.924369</td>\n",
       "      <td>12.187728</td>\n",
       "      <td>37.578261</td>\n",
       "      <td>36.973525</td>\n",
       "      <td>...</td>\n",
       "      <td>6.218302</td>\n",
       "      <td>2.639724</td>\n",
       "      <td>7.159558</td>\n",
       "      <td>8.901293</td>\n",
       "      <td>8.922766</td>\n",
       "      <td>-5.905553</td>\n",
       "      <td>-2.390585</td>\n",
       "      <td>2.293491</td>\n",
       "      <td>-0.907613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.159055</td>\n",
       "      <td>1.566221</td>\n",
       "      <td>-1.420570</td>\n",
       "      <td>1.631855</td>\n",
       "      <td>-2.466665</td>\n",
       "      <td>5.927075</td>\n",
       "      <td>15.041635</td>\n",
       "      <td>12.578331</td>\n",
       "      <td>24.624394</td>\n",
       "      <td>33.269776</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.902092</td>\n",
       "      <td>-1.964432</td>\n",
       "      <td>2.307943</td>\n",
       "      <td>-2.809301</td>\n",
       "      <td>-0.152702</td>\n",
       "      <td>3.559455</td>\n",
       "      <td>-2.590948</td>\n",
       "      <td>-1.439262</td>\n",
       "      <td>-1.778698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.305296</td>\n",
       "      <td>5.015556</td>\n",
       "      <td>0.228285</td>\n",
       "      <td>0.169621</td>\n",
       "      <td>-2.485127</td>\n",
       "      <td>4.234853</td>\n",
       "      <td>13.182361</td>\n",
       "      <td>9.575053</td>\n",
       "      <td>15.555193</td>\n",
       "      <td>27.697926</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.614588</td>\n",
       "      <td>-7.309828</td>\n",
       "      <td>4.694766</td>\n",
       "      <td>-6.028378</td>\n",
       "      <td>-12.928297</td>\n",
       "      <td>2.453018</td>\n",
       "      <td>-1.538861</td>\n",
       "      <td>5.416194</td>\n",
       "      <td>-6.698281</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.106394</td>\n",
       "      <td>-6.859777</td>\n",
       "      <td>-3.049865</td>\n",
       "      <td>1.528136</td>\n",
       "      <td>0.507199</td>\n",
       "      <td>-5.833811</td>\n",
       "      <td>7.790771</td>\n",
       "      <td>13.168363</td>\n",
       "      <td>38.031913</td>\n",
       "      <td>36.830638</td>\n",
       "      <td>...</td>\n",
       "      <td>3.225038</td>\n",
       "      <td>-1.006926</td>\n",
       "      <td>-6.063329</td>\n",
       "      <td>9.916437</td>\n",
       "      <td>-5.901981</td>\n",
       "      <td>-7.003289</td>\n",
       "      <td>-7.145146</td>\n",
       "      <td>1.530199</td>\n",
       "      <td>1.970310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-3.903271</td>\n",
       "      <td>12.191566</td>\n",
       "      <td>9.006009</td>\n",
       "      <td>-9.259527</td>\n",
       "      <td>-1.997461</td>\n",
       "      <td>-7.637875</td>\n",
       "      <td>10.095003</td>\n",
       "      <td>-1.511613</td>\n",
       "      <td>-7.952817</td>\n",
       "      <td>5.358870</td>\n",
       "      <td>...</td>\n",
       "      <td>8.770708</td>\n",
       "      <td>1.793150</td>\n",
       "      <td>1.792784</td>\n",
       "      <td>-0.852850</td>\n",
       "      <td>-2.160316</td>\n",
       "      <td>-5.593881</td>\n",
       "      <td>-4.084236</td>\n",
       "      <td>-3.240951</td>\n",
       "      <td>-1.233067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>-4.927434</td>\n",
       "      <td>11.608205</td>\n",
       "      <td>8.619548</td>\n",
       "      <td>-10.411061</td>\n",
       "      <td>-1.483200</td>\n",
       "      <td>-6.530006</td>\n",
       "      <td>9.904218</td>\n",
       "      <td>-2.186515</td>\n",
       "      <td>-7.529064</td>\n",
       "      <td>4.991597</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.351804</td>\n",
       "      <td>-2.918117</td>\n",
       "      <td>0.505993</td>\n",
       "      <td>-1.763750</td>\n",
       "      <td>3.021983</td>\n",
       "      <td>0.779503</td>\n",
       "      <td>2.327977</td>\n",
       "      <td>-1.431041</td>\n",
       "      <td>-0.700881</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-5.828013</td>\n",
       "      <td>7.678266</td>\n",
       "      <td>8.622503</td>\n",
       "      <td>-11.840058</td>\n",
       "      <td>0.899941</td>\n",
       "      <td>-22.822770</td>\n",
       "      <td>0.188729</td>\n",
       "      <td>-5.741302</td>\n",
       "      <td>-1.425461</td>\n",
       "      <td>-0.774465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029810</td>\n",
       "      <td>-2.946962</td>\n",
       "      <td>-0.240642</td>\n",
       "      <td>-0.390996</td>\n",
       "      <td>3.000510</td>\n",
       "      <td>-0.172166</td>\n",
       "      <td>-1.983885</td>\n",
       "      <td>0.187365</td>\n",
       "      <td>-1.894125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-2.749447</td>\n",
       "      <td>7.552831</td>\n",
       "      <td>10.715735</td>\n",
       "      <td>-12.019985</td>\n",
       "      <td>-0.782433</td>\n",
       "      <td>-22.687972</td>\n",
       "      <td>0.103086</td>\n",
       "      <td>-3.374163</td>\n",
       "      <td>-3.310945</td>\n",
       "      <td>0.747716</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.672627</td>\n",
       "      <td>1.009514</td>\n",
       "      <td>-1.365493</td>\n",
       "      <td>-1.592501</td>\n",
       "      <td>-0.037684</td>\n",
       "      <td>1.844884</td>\n",
       "      <td>0.250539</td>\n",
       "      <td>-0.843542</td>\n",
       "      <td>1.717097</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-5.752605</td>\n",
       "      <td>6.281290</td>\n",
       "      <td>6.409522</td>\n",
       "      <td>-9.728141</td>\n",
       "      <td>0.811689</td>\n",
       "      <td>-20.508088</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>-6.573662</td>\n",
       "      <td>-0.947335</td>\n",
       "      <td>-2.000914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044807</td>\n",
       "      <td>0.379536</td>\n",
       "      <td>7.050548</td>\n",
       "      <td>-3.179760</td>\n",
       "      <td>-1.116141</td>\n",
       "      <td>-0.221036</td>\n",
       "      <td>1.375558</td>\n",
       "      <td>1.328011</td>\n",
       "      <td>1.559158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 151 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5  \\\n",
       "0    4.346558  -4.687576  -6.215062   5.370536 -1.404635  -4.559129   \n",
       "1    1.123418  -6.398258  -5.925861   1.778670 -1.360708  -1.191740   \n",
       "2    2.159055   1.566221  -1.420570   1.631855 -2.466665   5.927075   \n",
       "3   -1.305296   5.015556   0.228285   0.169621 -2.485127   4.234853   \n",
       "4    0.106394  -6.859777  -3.049865   1.528136  0.507199  -5.833811   \n",
       "..        ...        ...        ...        ...       ...        ...   \n",
       "543 -3.903271  12.191566   9.006009  -9.259527 -1.997461  -7.637875   \n",
       "544 -4.927434  11.608205   8.619548 -10.411061 -1.483200  -6.530006   \n",
       "545 -5.828013   7.678266   8.622503 -11.840058  0.899941 -22.822770   \n",
       "546 -2.749447   7.552831  10.715735 -12.019985 -0.782433 -22.687972   \n",
       "547 -5.752605   6.281290   6.409522  -9.728141  0.811689 -20.508088   \n",
       "\n",
       "             6          7          8          9  ...       141       142  \\\n",
       "0    13.821442  16.252597  49.966649  51.039385  ...  2.896040  1.992734   \n",
       "1     7.924369  12.187728  37.578261  36.973525  ...  6.218302  2.639724   \n",
       "2    15.041635  12.578331  24.624394  33.269776  ... -1.902092 -1.964432   \n",
       "3    13.182361   9.575053  15.555193  27.697926  ... -6.614588 -7.309828   \n",
       "4     7.790771  13.168363  38.031913  36.830638  ...  3.225038 -1.006926   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "543  10.095003  -1.511613  -7.952817   5.358870  ...  8.770708  1.793150   \n",
       "544   9.904218  -2.186515  -7.529064   4.991597  ... -2.351804 -2.918117   \n",
       "545   0.188729  -5.741302  -1.425461  -0.774465  ...  0.029810 -2.946962   \n",
       "546   0.103086  -3.374163  -3.310945   0.747716  ... -1.672627  1.009514   \n",
       "547   0.077337  -6.573662  -0.947335  -2.000914  ... -0.044807  0.379536   \n",
       "\n",
       "          143       144        145       146       147       148       149  \\\n",
       "0   -1.870281  0.705100   6.747039  1.281073 -2.736667 -2.002284 -2.784893   \n",
       "1    7.159558  8.901293   8.922766 -5.905553 -2.390585  2.293491 -0.907613   \n",
       "2    2.307943 -2.809301  -0.152702  3.559455 -2.590948 -1.439262 -1.778698   \n",
       "3    4.694766 -6.028378 -12.928297  2.453018 -1.538861  5.416194 -6.698281   \n",
       "4   -6.063329  9.916437  -5.901981 -7.003289 -7.145146  1.530199  1.970310   \n",
       "..        ...       ...        ...       ...       ...       ...       ...   \n",
       "543  1.792784 -0.852850  -2.160316 -5.593881 -4.084236 -3.240951 -1.233067   \n",
       "544  0.505993 -1.763750   3.021983  0.779503  2.327977 -1.431041 -0.700881   \n",
       "545 -0.240642 -0.390996   3.000510 -0.172166 -1.983885  0.187365 -1.894125   \n",
       "546 -1.365493 -1.592501  -0.037684  1.844884  0.250539 -0.843542  1.717097   \n",
       "547  7.050548 -3.179760  -1.116141 -0.221036  1.375558  1.328011  1.559158   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "..      ...  \n",
       "543       1  \n",
       "544       0  \n",
       "545       1  \n",
       "546       0  \n",
       "547       1  \n",
       "\n",
       "[548 rows x 151 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_df = pca_df(bag_of_words)\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary of ML Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'Logistic Regression' : LogisticRegression(), \n",
    "    'Support Vector Machine': LinearSVC(max_iter=1000000),\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Empty Dataframe to Store Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_df(parameters, estimators):\n",
    "    # Empty lists to add estimator models and model selection types as column labels\n",
    "    methods = []\n",
    "    models = []\n",
    "\n",
    "    # Add to column names using estimators dictionary\n",
    "    for parameter in parameters:\n",
    "        for key, value in estimators.items():\n",
    "            methods.append(parameter)\n",
    "            models.append(key)\n",
    "\n",
    "    # Performance metrics for each target value (0: Decrease, 1: Increase)\n",
    "    report_keys = ['0', '1']\n",
    "\n",
    "    # Different metrics and grouping functions\n",
    "    report_agg = ['macro avg', 'weighted avg']\n",
    "    report_values = ['precision', 'recall', 'f1-score', 'support']\n",
    "\n",
    "    # Initialize empty lists to add metric names\n",
    "    column_idx = []\n",
    "    column_metric = []\n",
    "\n",
    "    # Add to list of row names\n",
    "    # For performance metrics based off of target value (0, 1)\n",
    "    for key in report_keys:\n",
    "        for value in report_values:\n",
    "            column_idx.append(key)\n",
    "            column_metric.append(value)\n",
    "\n",
    "    # For accuracy performance metric\n",
    "    column_idx.append('all')\n",
    "    column_metric.append('accuracy')\n",
    "\n",
    "    # For aggregate performance metrics\n",
    "    for agg in report_agg:\n",
    "        for value in report_values:\n",
    "            column_idx.append(agg)\n",
    "            column_metric.append(value)\n",
    "            \n",
    "    # Define columns and rows (indices) for empty dataframe\n",
    "    columns = [methods, models]\n",
    "    indices = [column_idx, column_metric]\n",
    "\n",
    "    # Fill dataframe with 0 values (to be replaced with actual performance metric values)\n",
    "    data = [ [0] * len(methods) for _ in range(len(column_idx))]\n",
    "\n",
    "    # Create dataframe to store evaluation metrics\n",
    "    performance = pd.DataFrame(data, columns = columns, index = indices)\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Cross-Validated GridSearch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">macro avg</th>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">weighted avg</th>\n",
       "      <th>precision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Base                         \\\n",
       "                       Logistic Regression Support Vector Machine   \n",
       "0            precision                   0                      0   \n",
       "             recall                      0                      0   \n",
       "             f1-score                    0                      0   \n",
       "             support                     0                      0   \n",
       "1            precision                   0                      0   \n",
       "             recall                      0                      0   \n",
       "             f1-score                    0                      0   \n",
       "             support                     0                      0   \n",
       "all          accuracy                    0                      0   \n",
       "macro avg    precision                   0                      0   \n",
       "             recall                      0                      0   \n",
       "             f1-score                    0                      0   \n",
       "             support                     0                      0   \n",
       "weighted avg precision                   0                      0   \n",
       "             recall                      0                      0   \n",
       "             f1-score                    0                      0   \n",
       "             support                     0                      0   \n",
       "\n",
       "                                                           \\\n",
       "                       Gaussian Naive Bayes Decision Tree   \n",
       "0            precision                    0             0   \n",
       "             recall                       0             0   \n",
       "             f1-score                     0             0   \n",
       "             support                      0             0   \n",
       "1            precision                    0             0   \n",
       "             recall                       0             0   \n",
       "             f1-score                     0             0   \n",
       "             support                      0             0   \n",
       "all          accuracy                     0             0   \n",
       "macro avg    precision                    0             0   \n",
       "             recall                       0             0   \n",
       "             f1-score                     0             0   \n",
       "             support                      0             0   \n",
       "weighted avg precision                    0             0   \n",
       "             recall                       0             0   \n",
       "             f1-score                     0             0   \n",
       "             support                      0             0   \n",
       "\n",
       "                       Cross-Validated GridSearch                         \\\n",
       "                              Logistic Regression Support Vector Machine   \n",
       "0            precision                          0                      0   \n",
       "             recall                             0                      0   \n",
       "             f1-score                           0                      0   \n",
       "             support                            0                      0   \n",
       "1            precision                          0                      0   \n",
       "             recall                             0                      0   \n",
       "             f1-score                           0                      0   \n",
       "             support                            0                      0   \n",
       "all          accuracy                           0                      0   \n",
       "macro avg    precision                          0                      0   \n",
       "             recall                             0                      0   \n",
       "             f1-score                           0                      0   \n",
       "             support                            0                      0   \n",
       "weighted avg precision                          0                      0   \n",
       "             recall                             0                      0   \n",
       "             f1-score                           0                      0   \n",
       "             support                            0                      0   \n",
       "\n",
       "                                                           \n",
       "                       Gaussian Naive Bayes Decision Tree  \n",
       "0            precision                    0             0  \n",
       "             recall                       0             0  \n",
       "             f1-score                     0             0  \n",
       "             support                      0             0  \n",
       "1            precision                    0             0  \n",
       "             recall                       0             0  \n",
       "             f1-score                     0             0  \n",
       "             support                      0             0  \n",
       "all          accuracy                     0             0  \n",
       "macro avg    precision                    0             0  \n",
       "             recall                       0             0  \n",
       "             f1-score                     0             0  \n",
       "             support                      0             0  \n",
       "weighted avg precision                    0             0  \n",
       "             recall                       0             0  \n",
       "             f1-score                     0             0  \n",
       "             support                      0             0  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = ['Base', 'Cross-Validated GridSearch']\n",
    "\n",
    "performance = metrics_df(parameters, estimators)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Add Evaluation Scores to Performance Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(method, estimator, model, predicted, y_test):\n",
    "    \"\"\" method: scaling, sampling, hyperparameter tuning, etc\n",
    "        estimator: different models (knn, decision tree, naive bayes)\n",
    "        model: trained model from given method and estimator\n",
    "        predicted: using model to run on test set and find predicitons\n",
    "        y_test: actual values corresponding to predictions\"\"\"\n",
    "    \n",
    "    # Find predicted and expected outcomes of model\n",
    "    expected = y_test\n",
    "    \n",
    "    # Calculate classification report corresponding to model\n",
    "    report = classification_report(y_true=expected, y_pred=predicted, output_dict=True)\n",
    "    \n",
    "    # Initialize empty list to append and store evaluation matrix values\n",
    "    data = []\n",
    "    \n",
    "    # Add in order of performance dataframe indices\n",
    "    # Append performance scores for target values (0, 1)\n",
    "    for i in range(2):\n",
    "        dct = report[str(i)]\n",
    "        for metric, value in dct.items():\n",
    "            data.append(value)\n",
    "    \n",
    "    # Append accuracy score\n",
    "    data.append(report['accuracy'])\n",
    "    \n",
    "    # Append aggregated performance scores\n",
    "    report_labels = ['macro avg', 'weighted avg']\n",
    "    for label in report_labels:\n",
    "        for metric, value in report[label].items():\n",
    "            data.append(value)\n",
    "    \n",
    "    # From data list, add in each value to corresponding spot in predefined performance dataframe\n",
    "    for i in range(len(data)):\n",
    "        performance[method, estimator].iloc[i] = data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_models(estimators, pca_df):\n",
    "    features = pca_df.drop(\"target\", axis = 1)\n",
    "    target = pca_df[\"target\"]\n",
    "\n",
    "    for estimator_name, estimator_object in estimators.items():\n",
    "        # split data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "        # select a classifier and create the model by fitting the training data\n",
    "        model = estimator_object.fit(X=X_train, y=y_train)\n",
    "\n",
    "        # prediction accuracy\n",
    "        accuracy_test = model.score(X_test, y_test)\n",
    "        accuracy_train = model.score(X_train, y_train)\n",
    "        predicted = model.predict(X=X_test)\n",
    "        print(estimator_name, \":\")\n",
    "        print(\"Prediction accuracy on the test data:\", f\"{accuracy_test:.2%}\", \"\\n\")\n",
    "        print(\"Prediction accuracy on the train data:\", f\"{accuracy_train:.2%}\", \"\\n\")\n",
    "        metrics('Base', estimator_name, model, predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression :\n",
      "Prediction accuracy on the test data: 63.50% \n",
      "\n",
      "Prediction accuracy on the train data: 87.83% \n",
      "\n",
      "Support Vector Machine :\n",
      "Prediction accuracy on the test data: 65.69% \n",
      "\n",
      "Prediction accuracy on the train data: 87.10% \n",
      "\n",
      "Gaussian Naive Bayes :\n",
      "Prediction accuracy on the test data: 66.42% \n",
      "\n",
      "Prediction accuracy on the train data: 71.78% \n",
      "\n",
      "Decision Tree :\n",
      "Prediction accuracy on the test data: 62.77% \n",
      "\n",
      "Prediction accuracy on the train data: 100.00% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "base_models(estimators, pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(estimator, param_grid):\n",
    "    \"\"\" estimator: model to test with (logistic regression, svm, guassian nb, decision tree)\n",
    "        param_grid: dictionary of different parameters and values to test and compare\"\"\"\n",
    "    features = pca_df.drop(\"target\", axis = 1)\n",
    "    target = pca_df[\"target\"]\n",
    "    \n",
    "    # Use grid search to find best parameters\n",
    "    method = estimators[estimator]\n",
    "    grid_search = GridSearchCV(method, param_grid, cv=5)\n",
    "    \n",
    "    # Split into train and test sets, fit with grid search\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, random_state = 3000)\n",
    "    model = grid_search.fit(X=X_train, y=y_train)\n",
    "    \n",
    "    # Print resulting best parameters and evaluation metrics\n",
    "    print(\"Best parameters: \", grid_search.best_params_)\n",
    "    \n",
    "    print(\"Test set score: \", grid_search.score(X_test, y_test)) \n",
    "    print(\"Training set score: \", grid_search.score(X_train, y_train))\n",
    "    \n",
    "    # Evaluate performance metric\n",
    "    predicted = grid_search.predict(X=X_test)\n",
    "    metrics('Cross-Validated GridSearch', estimator, model, predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/optimize.py:202: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.05, 'solver': 'newton-cg'}\n",
      "Test set score:  0.656934306569343\n",
      "Training set score:  0.8734793187347932\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Logistic Regression\n",
    "param_grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'C': [0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]}\n",
    "grid_search('Logistic Regression', param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 0.005}\n",
      "Test set score:  0.6788321167883211\n",
      "Training set score:  0.878345498783455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for SVM\n",
    "param_grid = {'C': [0.0001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]}\n",
    "grid_search('Support Vector Machine', param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'var_smoothing': 0.657933224657568}\n",
      "Test set score:  0.583941605839416\n",
      "Training set score:  0.6155717761557178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Naive Bayes\n",
    "param_grid = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "grid_search('Gaussian Naive Bayes', param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2}\n",
      "Test set score:  0.6204379562043796\n",
      "Training set score:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Decision Tree\n",
    "param_grid = {'criterion':['gini', 'entropy'], 'max_depth':[1, 10, 100, 120], 'min_samples_split': [2, 5, 10, 50, 100]}\n",
    "grid_search('Decision Tree', param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Base</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Cross-Validated GridSearch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Support Vector Machine</th>\n",
       "      <th>Gaussian Naive Bayes</th>\n",
       "      <th>Decision Tree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.626866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.971014</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.684564</td>\n",
       "      <td>0.712500</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.680272</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.617647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.614286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.632353</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.632353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.629921</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.313253</td>\n",
       "      <td>0.623188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.620438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">macro avg</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.636688</td>\n",
       "      <td>0.660855</td>\n",
       "      <td>0.682752</td>\n",
       "      <td>0.627771</td>\n",
       "      <td>0.659496</td>\n",
       "      <td>0.682562</td>\n",
       "      <td>0.707923</td>\n",
       "      <td>0.620576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.634591</td>\n",
       "      <td>0.656330</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.627771</td>\n",
       "      <td>0.656436</td>\n",
       "      <td>0.678282</td>\n",
       "      <td>0.581095</td>\n",
       "      <td>0.620524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.633455</td>\n",
       "      <td>0.654282</td>\n",
       "      <td>0.654496</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.655097</td>\n",
       "      <td>0.676748</td>\n",
       "      <td>0.507412</td>\n",
       "      <td>0.620418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">weighted avg</th>\n",
       "      <th>precision</th>\n",
       "      <td>0.636591</td>\n",
       "      <td>0.660685</td>\n",
       "      <td>0.682341</td>\n",
       "      <td>0.627804</td>\n",
       "      <td>0.659361</td>\n",
       "      <td>0.682385</td>\n",
       "      <td>0.706765</td>\n",
       "      <td>0.620622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.664234</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.656934</td>\n",
       "      <td>0.678832</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.620438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.633630</td>\n",
       "      <td>0.654503</td>\n",
       "      <td>0.654919</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.655280</td>\n",
       "      <td>0.676938</td>\n",
       "      <td>0.508829</td>\n",
       "      <td>0.620398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>137.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Base                         \\\n",
       "                       Logistic Regression Support Vector Machine   \n",
       "0            precision            0.623377               0.637500   \n",
       "             recall               0.695652               0.739130   \n",
       "             f1-score             0.657534               0.684564   \n",
       "             support             69.000000              69.000000   \n",
       "1            precision            0.650000               0.684211   \n",
       "             recall               0.573529               0.573529   \n",
       "             f1-score             0.609375               0.624000   \n",
       "             support             68.000000              68.000000   \n",
       "all          accuracy             0.635036               0.656934   \n",
       "macro avg    precision            0.636688               0.660855   \n",
       "             recall               0.634591               0.656330   \n",
       "             f1-score             0.633455               0.654282   \n",
       "             support            137.000000             137.000000   \n",
       "weighted avg precision            0.636591               0.660685   \n",
       "             recall               0.635036               0.656934   \n",
       "             f1-score             0.633630               0.654503   \n",
       "             support            137.000000             137.000000   \n",
       "\n",
       "                                                           \\\n",
       "                       Gaussian Naive Bayes Decision Tree   \n",
       "0            precision             0.626374      0.632353   \n",
       "             recall                0.826087      0.623188   \n",
       "             f1-score              0.712500      0.627737   \n",
       "             support              69.000000     69.000000   \n",
       "1            precision             0.739130      0.623188   \n",
       "             recall                0.500000      0.632353   \n",
       "             f1-score              0.596491      0.627737   \n",
       "             support              68.000000     68.000000   \n",
       "all          accuracy              0.664234      0.627737   \n",
       "macro avg    precision             0.682752      0.627771   \n",
       "             recall                0.663043      0.627771   \n",
       "             f1-score              0.654496      0.627737   \n",
       "             support             137.000000    137.000000   \n",
       "weighted avg precision             0.682341      0.627804   \n",
       "             recall                0.664234      0.627737   \n",
       "             f1-score              0.654919      0.627737   \n",
       "             support             137.000000    137.000000   \n",
       "\n",
       "                       Cross-Validated GridSearch                         \\\n",
       "                              Logistic Regression Support Vector Machine   \n",
       "0            precision                   0.641026               0.658228   \n",
       "             recall                      0.724638               0.753623   \n",
       "             f1-score                    0.680272               0.702703   \n",
       "             support                    69.000000              69.000000   \n",
       "1            precision                   0.677966               0.706897   \n",
       "             recall                      0.588235               0.602941   \n",
       "             f1-score                    0.629921               0.650794   \n",
       "             support                    68.000000              68.000000   \n",
       "all          accuracy                    0.656934               0.678832   \n",
       "macro avg    precision                   0.659496               0.682562   \n",
       "             recall                      0.656436               0.678282   \n",
       "             f1-score                    0.655097               0.676748   \n",
       "             support                   137.000000             137.000000   \n",
       "weighted avg precision                   0.659361               0.682385   \n",
       "             recall                      0.656934               0.678832   \n",
       "             f1-score                    0.655280               0.676938   \n",
       "             support                   137.000000             137.000000   \n",
       "\n",
       "                                                           \n",
       "                       Gaussian Naive Bayes Decision Tree  \n",
       "0            precision             0.549180      0.626866  \n",
       "             recall                0.971014      0.608696  \n",
       "             f1-score              0.701571      0.617647  \n",
       "             support              69.000000     69.000000  \n",
       "1            precision             0.866667      0.614286  \n",
       "             recall                0.191176      0.632353  \n",
       "             f1-score              0.313253      0.623188  \n",
       "             support              68.000000     68.000000  \n",
       "all          accuracy              0.583942      0.620438  \n",
       "macro avg    precision             0.707923      0.620576  \n",
       "             recall                0.581095      0.620524  \n",
       "             f1-score              0.507412      0.620418  \n",
       "             support             137.000000    137.000000  \n",
       "weighted avg precision             0.706765      0.620622  \n",
       "             recall                0.583942      0.620438  \n",
       "             f1-score              0.508829      0.620398  \n",
       "             support             137.000000    137.000000  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save evaluation metrics dataframe as csv\n",
    "performance.to_csv('model_evaluation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce all of the four classifiers, then can compare results and see which has the greatest accuracy \n",
    "def k_fold_cv(estimators):\n",
    "    features = pca_df.drop(\"target\", axis = 1)\n",
    "    target = pca_df[\"target\"]\n",
    "    \n",
    "    for estimator_name, estimator_object in estimators.items(): \n",
    "        kfold = KFold(n_splits = 10, random_state = 3000, shuffle = True)\n",
    "        scores = cross_val_score(estimator = estimator_object, X=features, y=target, cv=kfold)\n",
    "        print(estimator_name + \": \\n\\t\" + f\"mean accuracy={scores.mean():.2%} \" + f\"standard deviation={scores.std():.2%}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/xinyuwu/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: \n",
      "\tmean accuracy=64.79% standard deviation=5.37%\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f8/d4gwjvws74db26qzz416hhj80000gn/T/ipykernel_53644/1060175596.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk_fold_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/f8/d4gwjvws74db26qzz416hhj80000gn/T/ipykernel_53644/1383949303.py\u001b[0m in \u001b[0;36mk_fold_cv\u001b[0;34m(estimators, features, target)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \\n\\t\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"mean accuracy={scores.mean():.2%} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"standard deviation={scores.std():.2%}\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[1;32m    441\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    244\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[1;32m    245\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[0;32m--> 246\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    247\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    248\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \u001b[0msolver_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_liblinear_solver_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k_fold_cv(estimators, features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piedist(df, title):\n",
    "    \"\"\" df: dataframe (resampling method)\n",
    "        title: name of resampling method, for pie chart title \"\"\"\n",
    "    target_labels = {0:'Decrease in Stock Price', 1:'Increase in stock price'}\n",
    "    colors = {0:'paleturquoise', 1:'darkcyan'}\n",
    "    \n",
    "    # Find counts for each target value\n",
    "    df_target_unique = df['target'].value_counts()\n",
    "    \n",
    "    # Create labels for pie chart\n",
    "    labels = []\n",
    "    palette = []\n",
    "    for index, row in zip(df_target_unique.index, df_target_unique):\n",
    "        labels.append(f'{target_labels[index]}: {row}')\n",
    "        palette.append(colors[index])\n",
    "\n",
    "    # Create pie plot of target value distribution\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "    plt.pie(df_target_unique, labels=labels, autopct='%1.1f%%' , colors=palette)\n",
    "    plt.title(f'Distribution of Target Values {title}', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "piedist(pca_df, '(Stock Price Change)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
