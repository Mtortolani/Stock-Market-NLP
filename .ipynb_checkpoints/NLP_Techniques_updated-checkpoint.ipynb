{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PdfCleaner import PdfCleaner\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PerformanceTesting import PerformanceTester\n",
    "import pdfplumber\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "class Transcripts:\n",
    "    def __init__(self, ticker):\n",
    "        self.ticker = ticker\n",
    "        xinyu = \"/Users/xinyuwu/Desktop/fall21/ds3500/DS3500-Final-Project\"\n",
    "        marco = \"C:/Users/mtort/Repositories/DS3500-Final-Project\"\n",
    "        emily = \"/Users/emilywang/Desktop/DS3500-Final-Project-main-2\"\n",
    "        kelly = \"/Users/kelly/Desktop/ds3500/DS3500-Final-Project\"\n",
    "        qi = \"\"\n",
    "        self.path = emily + \"/transcripts/\"+ticker+\"_transcripts/\"\n",
    "\n",
    "    def read_files(self):\n",
    "        return [f for f in listdir(self.path) if isfile(join(self.path, f))]\n",
    "\n",
    "    def create_dct(self):\n",
    "        lst_files = self.read_files()\n",
    "        lst_cleaned = []\n",
    "        for file in lst_files:\n",
    "            file_path = self.path + file\n",
    "            if file_path[-3:] == 'pdf':\n",
    "                txt = PdfCleaner(file_path)\n",
    "                date = file[:8]\n",
    "                # txt_cleaned = txt.clean_stopwords_punctuation()\n",
    "                txt_cleaned = txt.clean_nums()\n",
    "                PerfTest = PerformanceTester()\n",
    "                PerfTest.setTimeframe('day', 1)\n",
    "                PerfTest.loadArticles([[self.ticker, date, txt_cleaned]])\n",
    "                try:\n",
    "                    classification_xy = PerfTest.aquireTargetValues()\n",
    "                except KeyError:\n",
    "                    print(f'''Warning: attempted to access market during weekend or after hours\n",
    "                          Earnings Transcript {file_path} Not Added\n",
    "                          ''')\n",
    "                    continue\n",
    "                dct_cleaned = {'price_change': classification_xy[1][0], 'name': self.ticker, 'date': date, 'transcript': txt_cleaned}\n",
    "                lst_cleaned.append(dct_cleaned)\n",
    "        return lst_cleaned\n",
    "\n",
    "class Database:\n",
    "    def __init__(self):\n",
    "        client = MongoClient()\n",
    "        client.drop_database('transcripts')\n",
    "        self.db = client.transcripts\n",
    "\n",
    "    def store_data(self, tickers_lst):\n",
    "        for t in tickers_lst:\n",
    "            store = Transcripts(t)\n",
    "            transcript = store.create_dct()\n",
    "            self.db.transcript.insert_many(transcript)\n",
    "            print(t + \" transcripts stored successfully\")\n",
    "        return self.db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526178.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/AAPL_transcripts/20161025_Apple_Inc-_Earnings_Call_2016-10-25_FS000000002309526172.pdf Not Added\n",
      "                          \n",
      "AAPL transcripts stored successfully\n",
      "ADBE transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/AMZN_transcripts/20190426_Amazon.com_Inc-_Earnings_Call_2019-4-25_DN000000002663104261.pdf Not Added\n",
      "                          \n",
      "AMZN transcripts stored successfully\n",
      "ASML transcripts stored successfully\n",
      "AVGO transcripts stored successfully\n",
      "CMCSA transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/COST_transcripts/20170303_COSTCO_WHOLESALE-_Earnings_Call_2017-3-2_FS000000002333920108.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/COST_transcripts/20170303_COSTCO_WHOLESALE-_Earnings_Call_2017-3-2_FS000000002333920096.pdf Not Added\n",
      "                          \n",
      "COST transcripts stored successfully\n",
      "CSCO transcripts stored successfully\n",
      "FB transcripts stored successfully\n",
      "GOOGL transcripts stored successfully\n",
      "INTC transcripts stored successfully\n",
      "MSFT transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/NFLX_transcripts/20190118_Netflix_Inc-_Earnings_Call_2019-1-17_DN000000002573718691.pdf Not Added\n",
      "                          \n",
      "NFLX transcripts stored successfully\n",
      "NVDA transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PDD_transcripts/20200522_Pinduoduo_Inc-_Earnings_Call_2020-5-22_DN000000002842636277.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PDD_transcripts/20200821_Pinduoduo_Inc-_Earnings_Call_2020-8-21_DN000000002890027659.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PDD_transcripts/20211126_Pinduoduo_Inc-_Earnings_Call_2021-11-26_RT000000002968946789.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PDD_transcripts/20180831_Pinduoduo_Inc-_Earnings_Call_2018-8-30_FS000000002463232018.pdf Not Added\n",
      "                          \n",
      "PDD transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PEP_transcripts/20190215_PepsiCo_Inc-_Earnings_Call_2019-2-15_FS000000002586060820.pdf Not Added\n",
      "                          \n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/PEP_transcripts/20190215_PepsiCo_Inc-_Earnings_Call_2019-2-15_FS000000002586060802.pdf Not Added\n",
      "                          \n",
      "PEP transcripts stored successfully\n",
      "PYPL transcripts stored successfully\n",
      "Warning: attempted to access market during weekend or after hours\n",
      "                          Earnings Transcript /Users/emilywang/Desktop/DS3500-Final-Project-main-2/transcripts/TMUS_transcripts/20190726_T_Mobile_US_Inc-_Earnings_Call_2019-7-26_DN000000002676607927.pdf Not Added\n",
      "                          \n",
      "TMUS transcripts stored successfully\n",
      "TSLA transcripts stored successfully\n",
      "TXN transcripts stored successfully\n"
     ]
    }
   ],
   "source": [
    "''' To prevent \"IOPub data rate exceeded error\":\n",
    "enter into terminal: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 '''\n",
    "\n",
    "tickers = ['AAPL', 'ADBE', 'AMZN', 'ASML', 'AVGO', 'CMCSA', 'COST',  'CSCO', 'FB', 'GOOGL',\n",
    "           'INTC', 'MSFT', 'NFLX', 'NVDA', 'PDD', 'PEP', 'PYPL', 'TMUS', 'TSLA', 'TXN']\n",
    "\n",
    "\n",
    "database = Database()\n",
    "db = database.store_data(tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aapl</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abating</th>\n",
       "      <th>...</th>\n",
       "      <th>ﬂuctuates</th>\n",
       "      <th>ﬂuctuation</th>\n",
       "      <th>ﬂuctuations</th>\n",
       "      <th>ﬂuid</th>\n",
       "      <th>ﬂuidity</th>\n",
       "      <th>ﬂush</th>\n",
       "      <th>ﬂux</th>\n",
       "      <th>ﬂy</th>\n",
       "      <th>ﬂying</th>\n",
       "      <th>ﬂywheel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104560</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 14903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aaa      aapl     aaron   ab  abandon  abandoned  abandonment  abate  \\\n",
       "0    0.0  0.180664  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "1    0.0  0.165782  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "2    0.0  0.104560  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "3    0.0  0.104032  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "4    0.0  0.182241  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "..   ...       ...       ...  ...      ...        ...          ...    ...   \n",
       "543  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "544  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "545  0.0  0.000000  0.027292  0.0      0.0        0.0          0.0    0.0   \n",
       "546  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "547  0.0  0.000000  0.000000  0.0      0.0        0.0          0.0    0.0   \n",
       "\n",
       "     abatement  abating  ...  ﬂuctuates  ﬂuctuation  ﬂuctuations      ﬂuid  \\\n",
       "0          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "1          0.0      0.0  ...        0.0         0.0     0.007406  0.009567   \n",
       "2          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "3          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "4          0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "..         ...      ...  ...        ...         ...          ...       ...   \n",
       "543        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "544        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "545        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "546        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "547        0.0      0.0  ...        0.0         0.0     0.000000  0.000000   \n",
       "\n",
       "     ﬂuidity  ﬂush  ﬂux   ﬂy  ﬂying  ﬂywheel  \n",
       "0        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "1        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "2        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "3        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "4        0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "..       ...   ...  ...  ...    ...      ...  \n",
       "543      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "544      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "545      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "546      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "547      0.0   0.0  0.0  0.0    0.0      0.0  \n",
       "\n",
       "[548 rows x 14903 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "''' Query to test on all transcripts '''\n",
    "all_companies = db.transcript.find()\n",
    "\n",
    "data = {}\n",
    "text = []\n",
    "\n",
    "for transcript in all_companies:\n",
    "    data[transcript[\"name\"]+\" \"+transcript[\"date\"]] = transcript[\"transcript\"]\n",
    "    text.append(transcript[\"transcript\"])\n",
    "#     print(transcript)\n",
    "#     df = pd.DataFrame.from_dict(data, orient ='index')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for name, info in data.items():\n",
    "''' Use countvectorizer to convert pdf text to a matrix of token counts '''\n",
    "# vect = CountVectorizer()\n",
    "# vect.fit(text)\n",
    "#     print(\"vocabulary: \\n\", vect.vocabulary_)\n",
    "\n",
    "\n",
    "''' Use bag of words to count how many times each word appears in pdf '''\n",
    "# bag_of_words = vect.transform(text)\n",
    "#     print(bag_of_words)\n",
    "\n",
    "    # number of times each unique word appears in this text\n",
    "# bag_of_words_arr = bag_of_words.toarray()\n",
    "# #     print(bag_of_words_arr)\n",
    "# feature_names = vect.get_feature_names()\n",
    "#     print(feature_names)\n",
    "\n",
    "''' Display occurrences in dataframe '''\n",
    "# bow_df = pd.DataFrame(bag_of_words_arr, columns = feature_names)\n",
    "# bow_df[\"Transcript (Company)\"] = \"APPL\"\n",
    "# bow_df.set_index(\"Transcript (Company & Date)\", inplace=True)\n",
    "\n",
    "''' Use Tfidf vectorizer to match words to TFIDF values '''\n",
    "\n",
    "vect = TfidfVectorizer(min_df=3, ngram_range = (1, 1)).fit(text)\n",
    "bag_of_words = vect.transform(text)\n",
    "feature_names = vect.get_feature_names()\n",
    "    \n",
    "tfidf_df = pd.DataFrame(bag_of_words.toarray(), columns = feature_names)\n",
    "# tfidf_df[name] = text\n",
    "# tfidf_df.set_index(name, inplace=True)\n",
    "\n",
    "# tfidf_df.head()\n",
    "    \n",
    "    \n",
    "# tfidfconverter = TfidfTransformer()\n",
    "# X = tfidfconverter.fit_transform(bag_of_words_arr).toarray()\n",
    "\n",
    "    \n",
    "# tfidf_df = pd.DataFrame(X, columns = feature_names)\n",
    "# tfidf_df[\"Transcript (Company)\"] = \"APPL\"\n",
    "# tfidf_df.set_index(\"Transcript (Company & Date)\", inplace=True)\n",
    "\n",
    "# ''' Show number of occurences of each word in one dataframe and tfidf (weighted) values of each word in another\n",
    "#     dataframe for each pdf '''\n",
    "# display(bow_df)\n",
    "display(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.344582</td>\n",
       "      <td>-4.686921</td>\n",
       "      <td>-6.216801</td>\n",
       "      <td>5.370494</td>\n",
       "      <td>-1.403301</td>\n",
       "      <td>-4.556711</td>\n",
       "      <td>13.813485</td>\n",
       "      <td>16.259708</td>\n",
       "      <td>49.957972</td>\n",
       "      <td>51.034496</td>\n",
       "      <td>...</td>\n",
       "      <td>1.751641</td>\n",
       "      <td>-2.908232</td>\n",
       "      <td>1.550937</td>\n",
       "      <td>2.705420</td>\n",
       "      <td>2.600625</td>\n",
       "      <td>1.150420</td>\n",
       "      <td>1.175590</td>\n",
       "      <td>-3.273358</td>\n",
       "      <td>0.823202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.124553</td>\n",
       "      <td>-6.399835</td>\n",
       "      <td>-5.928730</td>\n",
       "      <td>1.776507</td>\n",
       "      <td>-1.359946</td>\n",
       "      <td>-1.180643</td>\n",
       "      <td>7.938191</td>\n",
       "      <td>12.186023</td>\n",
       "      <td>37.580248</td>\n",
       "      <td>36.984635</td>\n",
       "      <td>...</td>\n",
       "      <td>5.941459</td>\n",
       "      <td>2.014945</td>\n",
       "      <td>1.564753</td>\n",
       "      <td>2.172956</td>\n",
       "      <td>-6.982889</td>\n",
       "      <td>-12.678266</td>\n",
       "      <td>-14.901542</td>\n",
       "      <td>7.278575</td>\n",
       "      <td>-2.237377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.158737</td>\n",
       "      <td>1.567013</td>\n",
       "      <td>-1.420503</td>\n",
       "      <td>1.631177</td>\n",
       "      <td>-2.466332</td>\n",
       "      <td>5.931245</td>\n",
       "      <td>15.031223</td>\n",
       "      <td>12.582518</td>\n",
       "      <td>24.621137</td>\n",
       "      <td>33.268088</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.314700</td>\n",
       "      <td>2.135892</td>\n",
       "      <td>1.922795</td>\n",
       "      <td>-1.634629</td>\n",
       "      <td>-0.403633</td>\n",
       "      <td>-2.380091</td>\n",
       "      <td>1.522753</td>\n",
       "      <td>2.251696</td>\n",
       "      <td>1.790942</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.306176</td>\n",
       "      <td>5.016410</td>\n",
       "      <td>0.228235</td>\n",
       "      <td>0.170695</td>\n",
       "      <td>-2.481837</td>\n",
       "      <td>4.231945</td>\n",
       "      <td>13.187201</td>\n",
       "      <td>9.571887</td>\n",
       "      <td>15.556912</td>\n",
       "      <td>27.703474</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.586793</td>\n",
       "      <td>7.709375</td>\n",
       "      <td>3.358040</td>\n",
       "      <td>-2.618940</td>\n",
       "      <td>-7.107106</td>\n",
       "      <td>-9.122895</td>\n",
       "      <td>3.129594</td>\n",
       "      <td>3.808548</td>\n",
       "      <td>-1.813825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104255</td>\n",
       "      <td>-6.860258</td>\n",
       "      <td>-3.052600</td>\n",
       "      <td>1.533432</td>\n",
       "      <td>0.507401</td>\n",
       "      <td>-5.834490</td>\n",
       "      <td>7.788784</td>\n",
       "      <td>13.164898</td>\n",
       "      <td>38.041960</td>\n",
       "      <td>36.843523</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.505617</td>\n",
       "      <td>-1.606170</td>\n",
       "      <td>2.689151</td>\n",
       "      <td>2.591582</td>\n",
       "      <td>-1.833403</td>\n",
       "      <td>4.690292</td>\n",
       "      <td>-1.386079</td>\n",
       "      <td>-10.312556</td>\n",
       "      <td>-2.621104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-3.904492</td>\n",
       "      <td>12.191947</td>\n",
       "      <td>9.006803</td>\n",
       "      <td>-9.258067</td>\n",
       "      <td>-1.993598</td>\n",
       "      <td>-7.636778</td>\n",
       "      <td>10.107436</td>\n",
       "      <td>-1.515442</td>\n",
       "      <td>-7.947448</td>\n",
       "      <td>5.350777</td>\n",
       "      <td>...</td>\n",
       "      <td>2.535080</td>\n",
       "      <td>2.841571</td>\n",
       "      <td>-5.229911</td>\n",
       "      <td>1.036249</td>\n",
       "      <td>-2.078197</td>\n",
       "      <td>-0.663822</td>\n",
       "      <td>-1.847672</td>\n",
       "      <td>-0.837835</td>\n",
       "      <td>-0.636704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>-4.926438</td>\n",
       "      <td>11.607215</td>\n",
       "      <td>8.622195</td>\n",
       "      <td>-10.409769</td>\n",
       "      <td>-1.484894</td>\n",
       "      <td>-6.527344</td>\n",
       "      <td>9.902574</td>\n",
       "      <td>-2.192730</td>\n",
       "      <td>-7.530926</td>\n",
       "      <td>4.994991</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.361426</td>\n",
       "      <td>-1.945094</td>\n",
       "      <td>1.188475</td>\n",
       "      <td>1.167356</td>\n",
       "      <td>1.185858</td>\n",
       "      <td>1.785701</td>\n",
       "      <td>6.373006</td>\n",
       "      <td>0.786635</td>\n",
       "      <td>2.977570</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>-5.827079</td>\n",
       "      <td>7.678023</td>\n",
       "      <td>8.623972</td>\n",
       "      <td>-11.840550</td>\n",
       "      <td>0.896756</td>\n",
       "      <td>-22.819610</td>\n",
       "      <td>0.181675</td>\n",
       "      <td>-5.743586</td>\n",
       "      <td>-1.430829</td>\n",
       "      <td>-0.770638</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.965059</td>\n",
       "      <td>-0.534589</td>\n",
       "      <td>0.954296</td>\n",
       "      <td>3.721015</td>\n",
       "      <td>-3.745957</td>\n",
       "      <td>-3.831627</td>\n",
       "      <td>7.738650</td>\n",
       "      <td>-0.225777</td>\n",
       "      <td>-1.060572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-2.749914</td>\n",
       "      <td>7.552572</td>\n",
       "      <td>10.714572</td>\n",
       "      <td>-12.020249</td>\n",
       "      <td>-0.784611</td>\n",
       "      <td>-22.688596</td>\n",
       "      <td>0.098813</td>\n",
       "      <td>-3.372035</td>\n",
       "      <td>-3.318664</td>\n",
       "      <td>0.754356</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.077073</td>\n",
       "      <td>-0.925765</td>\n",
       "      <td>0.283474</td>\n",
       "      <td>0.597827</td>\n",
       "      <td>-0.711961</td>\n",
       "      <td>0.929661</td>\n",
       "      <td>-0.292247</td>\n",
       "      <td>-0.836488</td>\n",
       "      <td>0.834402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-5.752025</td>\n",
       "      <td>6.280968</td>\n",
       "      <td>6.407773</td>\n",
       "      <td>-9.729696</td>\n",
       "      <td>0.809220</td>\n",
       "      <td>-20.508939</td>\n",
       "      <td>0.072370</td>\n",
       "      <td>-6.568272</td>\n",
       "      <td>-0.952860</td>\n",
       "      <td>-1.998308</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.589243</td>\n",
       "      <td>3.919134</td>\n",
       "      <td>6.511146</td>\n",
       "      <td>-0.484822</td>\n",
       "      <td>-8.702862</td>\n",
       "      <td>0.590689</td>\n",
       "      <td>-6.901046</td>\n",
       "      <td>1.545261</td>\n",
       "      <td>-0.537711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5  \\\n",
       "0    4.344582  -4.686921  -6.216801   5.370494 -1.403301  -4.556711   \n",
       "1    1.124553  -6.399835  -5.928730   1.776507 -1.359946  -1.180643   \n",
       "2    2.158737   1.567013  -1.420503   1.631177 -2.466332   5.931245   \n",
       "3   -1.306176   5.016410   0.228235   0.170695 -2.481837   4.231945   \n",
       "4    0.104255  -6.860258  -3.052600   1.533432  0.507401  -5.834490   \n",
       "..        ...        ...        ...        ...       ...        ...   \n",
       "543 -3.904492  12.191947   9.006803  -9.258067 -1.993598  -7.636778   \n",
       "544 -4.926438  11.607215   8.622195 -10.409769 -1.484894  -6.527344   \n",
       "545 -5.827079   7.678023   8.623972 -11.840550  0.896756 -22.819610   \n",
       "546 -2.749914   7.552572  10.714572 -12.020249 -0.784611 -22.688596   \n",
       "547 -5.752025   6.280968   6.407773  -9.729696  0.809220 -20.508939   \n",
       "\n",
       "             6          7          8          9  ...       191       192  \\\n",
       "0    13.813485  16.259708  49.957972  51.034496  ...  1.751641 -2.908232   \n",
       "1     7.938191  12.186023  37.580248  36.984635  ...  5.941459  2.014945   \n",
       "2    15.031223  12.582518  24.621137  33.268088  ... -1.314700  2.135892   \n",
       "3    13.187201   9.571887  15.556912  27.703474  ... -1.586793  7.709375   \n",
       "4     7.788784  13.164898  38.041960  36.843523  ... -2.505617 -1.606170   \n",
       "..         ...        ...        ...        ...  ...       ...       ...   \n",
       "543  10.107436  -1.515442  -7.947448   5.350777  ...  2.535080  2.841571   \n",
       "544   9.902574  -2.192730  -7.530926   4.994991  ... -3.361426 -1.945094   \n",
       "545   0.181675  -5.743586  -1.430829  -0.770638  ... -2.965059 -0.534589   \n",
       "546   0.098813  -3.372035  -3.318664   0.754356  ... -1.077073 -0.925765   \n",
       "547   0.072370  -6.568272  -0.952860  -1.998308  ... -3.589243  3.919134   \n",
       "\n",
       "          193       194       195        196        197        198       199  \\\n",
       "0    1.550937  2.705420  2.600625   1.150420   1.175590  -3.273358  0.823202   \n",
       "1    1.564753  2.172956 -6.982889 -12.678266 -14.901542   7.278575 -2.237377   \n",
       "2    1.922795 -1.634629 -0.403633  -2.380091   1.522753   2.251696  1.790942   \n",
       "3    3.358040 -2.618940 -7.107106  -9.122895   3.129594   3.808548 -1.813825   \n",
       "4    2.689151  2.591582 -1.833403   4.690292  -1.386079 -10.312556 -2.621104   \n",
       "..        ...       ...       ...        ...        ...        ...       ...   \n",
       "543 -5.229911  1.036249 -2.078197  -0.663822  -1.847672  -0.837835 -0.636704   \n",
       "544  1.188475  1.167356  1.185858   1.785701   6.373006   0.786635  2.977570   \n",
       "545  0.954296  3.721015 -3.745957  -3.831627   7.738650  -0.225777 -1.060572   \n",
       "546  0.283474  0.597827 -0.711961   0.929661  -0.292247  -0.836488  0.834402   \n",
       "547  6.511146 -0.484822 -8.702862   0.590689  -6.901046   1.545261 -0.537711   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         1  \n",
       "3         1  \n",
       "4         0  \n",
       "..      ...  \n",
       "543       1  \n",
       "544       0  \n",
       "545       1  \n",
       "546       0  \n",
       "547       1  \n",
       "\n",
       "[548 rows x 201 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "''' Using PCA to reduce total number of features before feeding into ML model '''\n",
    "# instantiate the PCA object and request reduced number of components (reduces number of columns/features)\n",
    "pca = PCA(n_components=200, random_state=3000)\n",
    "\n",
    "\n",
    "# standardize the features so they are all on the same scale\n",
    "features_standardized = StandardScaler().fit_transform(bag_of_words.toarray())\n",
    "\n",
    "# transform the standardized features using the PCA algorithm \n",
    "reduced_data = pca.fit_transform(features_standardized)\n",
    "\n",
    "# show transformed results in dataframe\n",
    "# components = [\"Component1\", \"Component2\", \"Component3\", \"Component4\", \"Component5\", \"Component6\",\n",
    "#              \"Component7\", \"Component8\", \"Component9\", \"Component10\"]\n",
    "\n",
    "pca_df = pd.DataFrame(reduced_data)#, columns = components)\n",
    "\n",
    "''' Obtain target values (whether stock price increased, decreased, or stayed the same) \n",
    "from database '''\n",
    "price_changes = []\n",
    "all_transcripts = db.transcript.find()\n",
    "for transcript in all_transcripts:\n",
    "    price_changes.append(transcript['price_change'])\n",
    "\n",
    "pca_df['target'] = price_changes \n",
    "\n",
    "pca_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the test data: 80.29%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "features = pca_df.drop(\"target\", axis = 1)\n",
    "target = pca_df[\"target\"]\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "#initialize classifier\n",
    "clf = LinearSVC(random_state=3000, max_iter=1000000)\n",
    "\n",
    "#create the model by fitting the training data\n",
    "clf.fit(X=X_train, y=y_train)\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print(\"Prediction accuracy on the test data:\", f\"{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction accuracy on the test data: 78.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilywang/opt/anaconda3/envs/geo/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=3000)\n",
    "\n",
    "#initialize classifier\n",
    "log = LogisticRegression(random_state=3000)\n",
    "\n",
    "#create the model by fitting the training data\n",
    "log.fit(X=X_train, y=y_train)\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = log.score(X_test, y_test)\n",
    "\n",
    "print(\"Prediction accuracy on the test data:\", f\"{accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
